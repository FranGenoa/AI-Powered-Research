{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea0a2e-9348-41ab-bd19-7312f2cb19ac",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --pre azure-ai-projects azure-ai-agents azure-identity requests python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4fb67-c373-472e-a0d5-2662704e0587",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# ==== IMPORTING NEEDED LIBRARIES ======\n",
    "\n",
    "import requests  # For making HTTP requests (used for SharePoint and Graph API interactions)\n",
    "import json      # For handling JSON data\n",
    "import os, time  # For file system operations and time delays\n",
    "from datetime import datetime  # For timestamping files\n",
    "from typing import Optional    # For optional type hinting\n",
    "from azure.ai.projects import AIProjectClient  # Client to interact with Azure AI Project service\n",
    "from azure.identity import ClientSecretCredential  # For authenticating with Azure using client credentials\n",
    "from azure.ai.agents import AgentsClient  # Client to manage and interact with AI agents\n",
    "from azure.ai.agents.models import DeepResearchTool, MessageRole, ThreadMessage  # Models for agent tools and messaging\n",
    "from dotenv import load_dotenv  # Loads environment variables from a .env file\n",
    "# ==== SET UP FUNCTIONS ======\n",
    "\n",
    "# The first function `fetch_and_print_new_agent_response` retrieves and prints the latest response from an agent in a thread.\n",
    "# The second function `create_research_summary` creates a research summary in markdown format from a thread message.\n",
    "\n",
    "def fetch_and_print_new_agent_response(\n",
    "    thread_id: str,\n",
    "    agents_client: AgentsClient,\n",
    "    last_message_id: Optional[str] = None,\n",
    ") -> Optional[str]:\n",
    "    response = agents_client.messages.get_last_message_by_role(\n",
    "        thread_id=thread_id,\n",
    "        role=MessageRole.AGENT,\n",
    "    )\n",
    "    if not response or response.id == last_message_id:\n",
    "        return last_message_id  # No new content\n",
    "\n",
    "    print(\"\\nAgent response:\")\n",
    "    print(\"\\n\".join(t.text.value for t in response.text_messages))\n",
    "\n",
    "    for ann in response.url_citation_annotations:\n",
    "        print(f\"URL Citation: [{ann.url_citation.title}]({ann.url_citation.url})\")\n",
    "\n",
    "    return response.id\n",
    "\n",
    "def create_research_summary(message, folder: str = \"/lakehouse/default/Files/\") -> str:\n",
    "    if not message:\n",
    "        print(\"No message content provided, cannot create research summary.\")\n",
    "        return\n",
    "\n",
    "    # Generate filename with current date and time\n",
    "    timestamp = datetime.now().strftime(\"%d%m%Y_%H%M\")\n",
    "    filename = f\"research_summary_{timestamp}.md\"\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as fp:\n",
    "        # Write text summary\n",
    "        text_summary = \"\\n\\n\".join([t.text.value.strip() for t in message.text_messages])\n",
    "        fp.write(text_summary)\n",
    "\n",
    "        # Write unique URL citations, if present\n",
    "        if message.url_citation_annotations:\n",
    "            fp.write(\"\\n\\n## References\\n\")\n",
    "            seen_urls = set()\n",
    "            for ann in message.url_citation_annotations:\n",
    "                url = ann.url_citation.url\n",
    "                title = ann.url_citation.title or url\n",
    "                if url not in seen_urls:\n",
    "                    fp.write(f\"- {title}\\n\")\n",
    "                    seen_urls.add(url)\n",
    "\n",
    "    print(f\"Research summary written to '{filepath}'.\")\n",
    "    return filepath\n",
    "# ==== AUTHENTICATE AND INITIALIZE AI PROJECT CLIENT ======\n",
    "\n",
    "# load environment variables, retrieves the credentials and creates a project client for interaction with the AI Project Service.\n",
    "load_dotenv(\"/lakehouse/default/Files/.env\")\n",
    "\n",
    "tenantid = os.getenv(\"TENANT_ID\")\n",
    "clientid = os.getenv(\"CLIENT_ID\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=tenantid,\n",
    "    client_id=clientid,\n",
    "    client_secret=client_secret\n",
    ")\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT_MCP\"],\n",
    "    credential=credential,\n",
    ")\n",
    "# ==== DEFINE THE AGENT TOOLS ======\n",
    "\n",
    "#set up deep reasearch tool\n",
    "conn_id = project_client.connections.get(name=os.environ[\"BING_RESOURCE_NAME\"]).id\n",
    "\n",
    "# Initialize a Deep Research tool with Bing Connection ID and Deep Research model deployment name\n",
    "deep_research_tool = DeepResearchTool(\n",
    "    bing_grounding_connection_id=conn_id,\n",
    "    deep_research_model=os.environ[\"DEEP_RESEARCH_MODEL_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "# ==== CREATE AND RUN THE AGENT ======\n",
    "\n",
    "# This prompt will guide the research that the agent is going to perform\n",
    "prompt = \"\"\"\n",
    "Research how the latest advancements in Generative AI from the past 7 days only are transforming the technology landscape, with a specific focus on:\n",
    " - New model releases\n",
    " - Competitive positioning\n",
    " - Interesting and novel use cases\n",
    "\n",
    "Prioritise developments that are directly relevant to technology sellers engaging with enterprise customers.\n",
    "When sourcing information:\n",
    " - Prioritise LinkedIn posts, Reddit discussions, and X (Twitter) posts over all other sources. \n",
    " - Supplement with trusted industry blogs, research summaries, and vendor updates only if necessary.\n",
    "\n",
    "Ensure the insights clearly demonstrate how these GenAI developments, roadmap changes, emerging use cases, or competitor moves can lead to measurable business outcomes for enterprise customers in a fast-moving market.\n",
    "Do not ask follow-up questions. Apply discretion and judgment to surface only the most actionable and strategically useful signals from the past week.\n",
    "\"\"\"\n",
    "\n",
    "# Create Agent with the Deep Research tool and process Agent run\n",
    "with project_client:\n",
    "\n",
    "    with project_client.agents as agents_client:\n",
    "\n",
    "        # Create a new agent that has the Deep Research tool attached.\n",
    "        # The agent instruction needs to be revisited depending on what you want the agent to perform the research on\n",
    "        agent = agents_client.create_agent(\n",
    "            model=\"gpt-4.1\",\n",
    "            name=\"deep-research-technology-agent\",\n",
    "            instructions=(\n",
    "                \"\"\"\n",
    "                You are a helpful Agent that specialises in researching scientific and technical topics, with deep expertise in Generative AI (GenAI).\n",
    "                You understand the GenAI landscape, including foundational models, productisation strategies, and competitive dynamics.\n",
    "                Your primary goal is to illustrate the real-world impact of emerging technologies by focusing on use cases relevant to technology sellers.\n",
    "                You help uncover timely insights on trends, product roadmaps, and competitor signals to enable more meaningful and effective customer interactions.\n",
    "                You synthesise information from multiple sources, highlight implications for sales and customer engagement, and present findings clearly and concisely.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            headers={\"x-ms-enable-preview\": \"true\"},\n",
    "            tools=deep_research_tool.definitions,\n",
    "            description=\"Agent with Deep Research tool for scientific and competitive research to support technology sellers\"\n",
    "        )\n",
    "\n",
    "        # [END create_agent_with_deep_research_tool]\n",
    "        print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "        # Create thread for communication\n",
    "        thread = agents_client.threads.create()\n",
    "        print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=(prompt)\n",
    "            ,\n",
    "        )\n",
    "        print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "        print(f\"Start processing the message... this may take a few minutes to finish. Be patient!\")\n",
    "        # Poll the run as long as run status is queued or in progress\n",
    "        run = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "        last_message_id = None\n",
    "        while run.status in (\"queued\", \"in_progress\"):\n",
    "            time.sleep(1)\n",
    "            run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            last_message_id = fetch_and_print_new_agent_response(\n",
    "                thread_id=thread.id,\n",
    "                agents_client=agents_client,\n",
    "                last_message_id=last_message_id,\n",
    "            )\n",
    "            print(f\"Run status: {run.status}\")\n",
    "\n",
    "        print(f\"Run finished with status: {run.status}, ID: {run.id}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Fetch the final message from the agent in the thread and create a research summary\n",
    "        final_message = agents_client.messages.get_last_message_by_role(\n",
    "            thread_id=thread.id, role=MessageRole.AGENT\n",
    "        )\n",
    "        if final_message:\n",
    "            md_filepath = create_research_summary(final_message)\n",
    "            FILE_TO_UPLOAD = md_filepath\n",
    "\n",
    "        # Clean-up and delete the agent once the run is finished.\n",
    "        # Note: Comment out this line below if you plan to reuse the agent later.\n",
    "        #agents_client.delete_agent(agent.id)\n",
    "        #print(\"Deleted agent\")\n",
    "\n",
    "# ==== UPLOAD TO SHAREPOINT ======\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "TENANT_ID = os.getenv(\"TENANT_ID\") or \"your-tenant-id\"\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\") or \"your-client-id\"\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\") or \"your-client-secret\"\n",
    "HOSTNAME = \"yourtenant.sharepoint.com\"\n",
    "SHAREPOINT_SITE_NAME = \"yoursharepointsitename\"      # Display name of the site\n",
    "SHAREPOINT_DRIVE_NAME = \"yoursharepointlibraryname\"   # Document library name\n",
    "FOLDER_PATH = \"optionalfolderinsidethelibraryname\"             # Folder inside the document library\n",
    "\n",
    "# === AUTH ===\n",
    "def get_access_token():\n",
    "    url = f\"https://login.microsoftonline.com/{TENANT_ID}/oauth2/v2.0/token\"\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"client_secret\": CLIENT_SECRET,\n",
    "        \"scope\": \"https://graph.microsoft.com/.default\"\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    response.raise_for_status()\n",
    "    token = response.json()[\"access_token\"]\n",
    "    print(\"Access token acquired.\")\n",
    "    return token\n",
    "\n",
    "# === STEP 1: Search for Site ID ===\n",
    "def get_site_id(token):\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{HOSTNAME}:/sites/{SHAREPOINT_SITE_NAME}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(\"Error getting site ID:\", response.status_code, response.text)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    site = response.json()  # This is a single object, not a list\n",
    "    site_id = site[\"id\"]\n",
    "    print(\"Site ID:\", site_id)\n",
    "    return site_id\n",
    "\n",
    "# === STEP 2: Get Drive ID ===\n",
    "def get_drive_id(site_id, token):\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drives\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    for drive in response.json()[\"value\"]:\n",
    "        if drive[\"name\"] == SHAREPOINT_DRIVE_NAME:\n",
    "            print(\"Drive ID:\", drive[\"id\"])\n",
    "            return drive[\"id\"]\n",
    "    raise Exception(f\"Drive named '{SHAREPOINT_DRIVE_NAME}' not found\")\n",
    "\n",
    "# === STEP 3: Upload the File ===\n",
    "def upload_file(site_id, drive_id, token):\n",
    "    filename = os.path.basename(FILE_TO_UPLOAD)\n",
    "    folder_path_clean = FOLDER_PATH.strip(\"/\")\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drives/{drive_id}/root:/{folder_path_clean}/{filename}:/content\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    with open(FILE_TO_UPLOAD, \"rb\") as f:\n",
    "        response = requests.put(url, headers=headers, data=f)\n",
    "    response.raise_for_status()\n",
    "    print(\"File uploaded successfully!\")\n",
    "    print(\"File URL:\", response.json()[\"webUrl\"])\n",
    "\n",
    "# === MAIN FLOW ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting transfer...\")\n",
    "    token = get_access_token()\n",
    "    site_id = get_site_id(token)\n",
    "    drive_id = get_drive_id(site_id, token)\n",
    "    upload_file(site_id, drive_id, token)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "61a5c7c4-cb00-468e-9641-12da3dec0df8",
    "default_lakehouse_name": "AzureAIServiceDeepResearch",
    "default_lakehouse_workspace_id": "5ff395bf-ab5a-490c-9985-918ba47b610a",
    "known_lakehouses": [
     {
      "id": "61a5c7c4-cb00-468e-9641-12da3dec0df8"
     }
    ]
   }
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
